{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/claudio.gauna/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepreplay.callbacks import ReplayData\n",
    "from deepreplay.datasets.parabola import load_data\n",
    "\n",
    "X, y = load_data()\n",
    "\n",
    "replaydata = ReplayData(X, y, filename='hyperparms_in_action.h5', group_name='part1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/claudio.gauna/anaconda3/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Epoch 1/150\n",
      "2000/2000 [==============================] - 1s 276us/step - loss: 0.6930 - acc: 0.5045\n",
      "Epoch 2/150\n",
      "2000/2000 [==============================] - 0s 98us/step - loss: 0.6917 - acc: 0.5390\n",
      "Epoch 3/150\n",
      "2000/2000 [==============================] - 0s 96us/step - loss: 0.6904 - acc: 0.5805\n",
      "Epoch 4/150\n",
      "2000/2000 [==============================] - 0s 136us/step - loss: 0.6885 - acc: 0.5560\n",
      "Epoch 5/150\n",
      "2000/2000 [==============================] - 0s 119us/step - loss: 0.6862 - acc: 0.6375\n",
      "Epoch 6/150\n",
      "2000/2000 [==============================] - 0s 114us/step - loss: 0.6828 - acc: 0.6780\n",
      "Epoch 7/150\n",
      "2000/2000 [==============================] - 0s 95us/step - loss: 0.6784 - acc: 0.6625\n",
      "Epoch 8/150\n",
      "2000/2000 [==============================] - 0s 91us/step - loss: 0.6725 - acc: 0.6850\n",
      "Epoch 9/150\n",
      "2000/2000 [==============================] - 0s 100us/step - loss: 0.6645 - acc: 0.7115\n",
      "Epoch 10/150\n",
      "2000/2000 [==============================] - 0s 97us/step - loss: 0.6533 - acc: 0.7010\n",
      "Epoch 11/150\n",
      "2000/2000 [==============================] - 0s 150us/step - loss: 0.6414 - acc: 0.7525\n",
      "Epoch 12/150\n",
      "2000/2000 [==============================] - 0s 111us/step - loss: 0.6266 - acc: 0.7225\n",
      "Epoch 13/150\n",
      "2000/2000 [==============================] - 0s 104us/step - loss: 0.6098 - acc: 0.7200\n",
      "Epoch 14/150\n",
      "2000/2000 [==============================] - 0s 96us/step - loss: 0.5915 - acc: 0.7235\n",
      "Epoch 15/150\n",
      "2000/2000 [==============================] - 0s 98us/step - loss: 0.5729 - acc: 0.7320\n",
      "Epoch 16/150\n",
      "2000/2000 [==============================] - 0s 108us/step - loss: 0.5546 - acc: 0.7355\n",
      "Epoch 17/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.5374 - acc: 0.7400\n",
      "Epoch 18/150\n",
      "2000/2000 [==============================] - 0s 126us/step - loss: 0.5216 - acc: 0.7440\n",
      "Epoch 19/150\n",
      "2000/2000 [==============================] - 0s 117us/step - loss: 0.5077 - acc: 0.7485\n",
      "Epoch 20/150\n",
      "2000/2000 [==============================] - 0s 117us/step - loss: 0.4957 - acc: 0.7455\n",
      "Epoch 21/150\n",
      "2000/2000 [==============================] - 0s 95us/step - loss: 0.4852 - acc: 0.7510\n",
      "Epoch 22/150\n",
      "2000/2000 [==============================] - 0s 96us/step - loss: 0.4764 - acc: 0.7555\n",
      "Epoch 23/150\n",
      "2000/2000 [==============================] - 0s 102us/step - loss: 0.4689 - acc: 0.7585\n",
      "Epoch 24/150\n",
      "2000/2000 [==============================] - 0s 93us/step - loss: 0.4625 - acc: 0.7545\n",
      "Epoch 25/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.4572 - acc: 0.7625\n",
      "Epoch 26/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.4527 - acc: 0.7630\n",
      "Epoch 27/150\n",
      "2000/2000 [==============================] - 0s 100us/step - loss: 0.4489 - acc: 0.7595\n",
      "Epoch 28/150\n",
      "2000/2000 [==============================] - 0s 136us/step - loss: 0.4455 - acc: 0.7665\n",
      "Epoch 29/150\n",
      "2000/2000 [==============================] - 0s 109us/step - loss: 0.4425 - acc: 0.7665\n",
      "Epoch 30/150\n",
      "2000/2000 [==============================] - 0s 100us/step - loss: 0.4400 - acc: 0.7665\n",
      "Epoch 31/150\n",
      "2000/2000 [==============================] - 0s 96us/step - loss: 0.4378 - acc: 0.7660\n",
      "Epoch 32/150\n",
      "2000/2000 [==============================] - 0s 101us/step - loss: 0.4357 - acc: 0.7665\n",
      "Epoch 33/150\n",
      "2000/2000 [==============================] - 0s 111us/step - loss: 0.4341 - acc: 0.7800\n",
      "Epoch 34/150\n",
      "2000/2000 [==============================] - 0s 93us/step - loss: 0.4324 - acc: 0.7725\n",
      "Epoch 35/150\n",
      "2000/2000 [==============================] - 0s 94us/step - loss: 0.4308 - acc: 0.7750\n",
      "Epoch 36/150\n",
      "2000/2000 [==============================] - 0s 120us/step - loss: 0.4294 - acc: 0.7720\n",
      "Epoch 37/150\n",
      "2000/2000 [==============================] - 0s 98us/step - loss: 0.4282 - acc: 0.7780\n",
      "Epoch 38/150\n",
      "2000/2000 [==============================] - 0s 95us/step - loss: 0.4268 - acc: 0.7710\n",
      "Epoch 39/150\n",
      "2000/2000 [==============================] - 0s 108us/step - loss: 0.4258 - acc: 0.7765\n",
      "Epoch 40/150\n",
      "2000/2000 [==============================] - 0s 102us/step - loss: 0.4248 - acc: 0.7805\n",
      "Epoch 41/150\n",
      "2000/2000 [==============================] - 0s 94us/step - loss: 0.4237 - acc: 0.7830\n",
      "Epoch 42/150\n",
      "2000/2000 [==============================] - 0s 94us/step - loss: 0.4227 - acc: 0.7825\n",
      "Epoch 43/150\n",
      "2000/2000 [==============================] - 0s 95us/step - loss: 0.4218 - acc: 0.7820\n",
      "Epoch 44/150\n",
      "2000/2000 [==============================] - 0s 136us/step - loss: 0.4209 - acc: 0.7840\n",
      "Epoch 45/150\n",
      "2000/2000 [==============================] - 0s 117us/step - loss: 0.4200 - acc: 0.7835\n",
      "Epoch 46/150\n",
      "2000/2000 [==============================] - 0s 112us/step - loss: 0.4189 - acc: 0.7895\n",
      "Epoch 47/150\n",
      "2000/2000 [==============================] - 0s 95us/step - loss: 0.4182 - acc: 0.7860\n",
      "Epoch 48/150\n",
      "2000/2000 [==============================] - 0s 96us/step - loss: 0.4172 - acc: 0.7950\n",
      "Epoch 49/150\n",
      "2000/2000 [==============================] - 0s 108us/step - loss: 0.4165 - acc: 0.7815\n",
      "Epoch 50/150\n",
      "2000/2000 [==============================] - 0s 94us/step - loss: 0.4155 - acc: 0.7940\n",
      "Epoch 51/150\n",
      "2000/2000 [==============================] - 0s 130us/step - loss: 0.4147 - acc: 0.7910\n",
      "Epoch 52/150\n",
      "2000/2000 [==============================] - 0s 113us/step - loss: 0.4137 - acc: 0.7945\n",
      "Epoch 53/150\n",
      "2000/2000 [==============================] - 0s 114us/step - loss: 0.4126 - acc: 0.7935\n",
      "Epoch 54/150\n",
      "2000/2000 [==============================] - 0s 116us/step - loss: 0.4116 - acc: 0.8020\n",
      "Epoch 55/150\n",
      "2000/2000 [==============================] - 0s 117us/step - loss: 0.4105 - acc: 0.8000\n",
      "Epoch 56/150\n",
      "2000/2000 [==============================] - 0s 113us/step - loss: 0.4093 - acc: 0.7940\n",
      "Epoch 57/150\n",
      "2000/2000 [==============================] - 0s 95us/step - loss: 0.4079 - acc: 0.7995\n",
      "Epoch 58/150\n",
      "2000/2000 [==============================] - 0s 99us/step - loss: 0.4064 - acc: 0.8125\n",
      "Epoch 59/150\n",
      "2000/2000 [==============================] - 0s 124us/step - loss: 0.4049 - acc: 0.8140\n",
      "Epoch 60/150\n",
      "2000/2000 [==============================] - 0s 120us/step - loss: 0.4030 - acc: 0.8010\n",
      "Epoch 61/150\n",
      "2000/2000 [==============================] - 0s 124us/step - loss: 0.4011 - acc: 0.8175\n",
      "Epoch 62/150\n",
      "2000/2000 [==============================] - 0s 111us/step - loss: 0.3988 - acc: 0.8170\n",
      "Epoch 63/150\n",
      "2000/2000 [==============================] - 0s 125us/step - loss: 0.3962 - acc: 0.8295\n",
      "Epoch 64/150\n",
      "2000/2000 [==============================] - 0s 112us/step - loss: 0.3932 - acc: 0.8235\n",
      "Epoch 65/150\n",
      "2000/2000 [==============================] - 0s 107us/step - loss: 0.3897 - acc: 0.8415\n",
      "Epoch 66/150\n",
      "2000/2000 [==============================] - 0s 95us/step - loss: 0.3857 - acc: 0.8560\n",
      "Epoch 67/150\n",
      "2000/2000 [==============================] - 0s 95us/step - loss: 0.3813 - acc: 0.8490\n",
      "Epoch 68/150\n",
      "2000/2000 [==============================] - 0s 99us/step - loss: 0.3763 - acc: 0.8610\n",
      "Epoch 69/150\n",
      "2000/2000 [==============================] - 0s 115us/step - loss: 0.3707 - acc: 0.8615\n",
      "Epoch 70/150\n",
      "2000/2000 [==============================] - 0s 113us/step - loss: 0.3645 - acc: 0.8650\n",
      "Epoch 71/150\n",
      "2000/2000 [==============================] - 0s 109us/step - loss: 0.3577 - acc: 0.8660\n",
      "Epoch 72/150\n",
      "2000/2000 [==============================] - 0s 96us/step - loss: 0.3502 - acc: 0.8665\n",
      "Epoch 73/150\n",
      "2000/2000 [==============================] - 0s 96us/step - loss: 0.3422 - acc: 0.8685\n",
      "Epoch 74/150\n",
      "2000/2000 [==============================] - 0s 111us/step - loss: 0.3337 - acc: 0.8705\n",
      "Epoch 75/150\n",
      "2000/2000 [==============================] - 0s 97us/step - loss: 0.3249 - acc: 0.8715\n",
      "Epoch 76/150\n",
      "2000/2000 [==============================] - 0s 94us/step - loss: 0.3157 - acc: 0.8730\n",
      "Epoch 77/150\n",
      "2000/2000 [==============================] - 0s 116us/step - loss: 0.3066 - acc: 0.8770\n",
      "Epoch 78/150\n",
      "2000/2000 [==============================] - 0s 110us/step - loss: 0.2972 - acc: 0.8810\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 114us/step - loss: 0.2876 - acc: 0.8840\n",
      "Epoch 80/150\n",
      "2000/2000 [==============================] - 0s 94us/step - loss: 0.2782 - acc: 0.8875\n",
      "Epoch 81/150\n",
      "2000/2000 [==============================] - 0s 115us/step - loss: 0.2690 - acc: 0.8935\n",
      "Epoch 82/150\n",
      "2000/2000 [==============================] - 0s 113us/step - loss: 0.2598 - acc: 0.8990\n",
      "Epoch 83/150\n",
      "2000/2000 [==============================] - 0s 109us/step - loss: 0.2510 - acc: 0.9020\n",
      "Epoch 84/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.2421 - acc: 0.9110\n",
      "Epoch 85/150\n",
      "2000/2000 [==============================] - 0s 114us/step - loss: 0.2337 - acc: 0.9230\n",
      "Epoch 86/150\n",
      "2000/2000 [==============================] - 0s 111us/step - loss: 0.2254 - acc: 0.9305\n",
      "Epoch 87/150\n",
      "2000/2000 [==============================] - 0s 108us/step - loss: 0.2172 - acc: 0.9410\n",
      "Epoch 88/150\n",
      "2000/2000 [==============================] - 0s 104us/step - loss: 0.2096 - acc: 0.9520\n",
      "Epoch 89/150\n",
      "2000/2000 [==============================] - 0s 111us/step - loss: 0.2022 - acc: 0.9645\n",
      "Epoch 90/150\n",
      "2000/2000 [==============================] - 0s 112us/step - loss: 0.1949 - acc: 0.9695\n",
      "Epoch 91/150\n",
      "2000/2000 [==============================] - 0s 95us/step - loss: 0.1880 - acc: 0.9770\n",
      "Epoch 92/150\n",
      "2000/2000 [==============================] - 0s 94us/step - loss: 0.1814 - acc: 0.9830\n",
      "Epoch 93/150\n",
      "2000/2000 [==============================] - 0s 117us/step - loss: 0.1750 - acc: 0.9895\n",
      "Epoch 94/150\n",
      "2000/2000 [==============================] - 0s 108us/step - loss: 0.1689 - acc: 0.9885\n",
      "Epoch 95/150\n",
      "2000/2000 [==============================] - 0s 101us/step - loss: 0.1631 - acc: 0.9940\n",
      "Epoch 96/150\n",
      "2000/2000 [==============================] - 0s 95us/step - loss: 0.1575 - acc: 0.9950\n",
      "Epoch 97/150\n",
      "2000/2000 [==============================] - 0s 113us/step - loss: 0.1522 - acc: 0.9960\n",
      "Epoch 98/150\n",
      "2000/2000 [==============================] - 0s 109us/step - loss: 0.1471 - acc: 0.9960\n",
      "Epoch 99/150\n",
      "2000/2000 [==============================] - 0s 107us/step - loss: 0.1422 - acc: 0.9970\n",
      "Epoch 100/150\n",
      "2000/2000 [==============================] - 0s 96us/step - loss: 0.1376 - acc: 0.9990\n",
      "Epoch 101/150\n",
      "2000/2000 [==============================] - 0s 111us/step - loss: 0.1332 - acc: 0.9985\n",
      "Epoch 102/150\n",
      "2000/2000 [==============================] - 0s 104us/step - loss: 0.1289 - acc: 0.9995\n",
      "Epoch 103/150\n",
      "2000/2000 [==============================] - 0s 94us/step - loss: 0.1249 - acc: 1.0000\n",
      "Epoch 104/150\n",
      "2000/2000 [==============================] - 0s 94us/step - loss: 0.1211 - acc: 1.0000\n",
      "Epoch 105/150\n",
      "2000/2000 [==============================] - 0s 97us/step - loss: 0.1174 - acc: 1.0000\n",
      "Epoch 106/150\n",
      "2000/2000 [==============================] - 0s 102us/step - loss: 0.1140 - acc: 1.0000\n",
      "Epoch 107/150\n",
      "2000/2000 [==============================] - 0s 100us/step - loss: 0.1106 - acc: 1.0000\n",
      "Epoch 108/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.1074 - acc: 1.0000\n",
      "Epoch 109/150\n",
      "2000/2000 [==============================] - 0s 160us/step - loss: 0.1044 - acc: 1.0000\n",
      "Epoch 110/150\n",
      "2000/2000 [==============================] - 0s 182us/step - loss: 0.1015 - acc: 1.0000\n",
      "Epoch 111/150\n",
      "2000/2000 [==============================] - 0s 96us/step - loss: 0.0987 - acc: 1.0000\n",
      "Epoch 112/150\n",
      "2000/2000 [==============================] - 0s 91us/step - loss: 0.0960 - acc: 1.0000\n",
      "Epoch 113/150\n",
      "2000/2000 [==============================] - 0s 103us/step - loss: 0.0935 - acc: 1.0000\n",
      "Epoch 114/150\n",
      "2000/2000 [==============================] - 0s 100us/step - loss: 0.0911 - acc: 1.0000\n",
      "Epoch 115/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.0887 - acc: 1.0000\n",
      "Epoch 116/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.0865 - acc: 1.0000\n",
      "Epoch 117/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.0844 - acc: 1.0000\n",
      "Epoch 118/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.0823 - acc: 1.0000\n",
      "Epoch 119/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.0804 - acc: 1.0000\n",
      "Epoch 120/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.0785 - acc: 1.0000\n",
      "Epoch 121/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.0766 - acc: 1.0000\n",
      "Epoch 122/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.0749 - acc: 1.0000\n",
      "Epoch 123/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.0732 - acc: 1.0000\n",
      "Epoch 124/150\n",
      "2000/2000 [==============================] - 0s 93us/step - loss: 0.0716 - acc: 1.0000\n",
      "Epoch 125/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.0701 - acc: 1.0000\n",
      "Epoch 126/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.0685 - acc: 1.0000\n",
      "Epoch 127/150\n",
      "2000/2000 [==============================] - 0s 93us/step - loss: 0.0671 - acc: 1.0000\n",
      "Epoch 128/150\n",
      "2000/2000 [==============================] - 0s 93us/step - loss: 0.0657 - acc: 1.0000\n",
      "Epoch 129/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.0644 - acc: 1.0000\n",
      "Epoch 130/150\n",
      "2000/2000 [==============================] - 0s 93us/step - loss: 0.0631 - acc: 1.0000\n",
      "Epoch 131/150\n",
      "2000/2000 [==============================] - 0s 99us/step - loss: 0.0618 - acc: 1.0000\n",
      "Epoch 132/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.0606 - acc: 1.0000\n",
      "Epoch 133/150\n",
      "2000/2000 [==============================] - 0s 91us/step - loss: 0.0594 - acc: 1.0000\n",
      "Epoch 134/150\n",
      "2000/2000 [==============================] - 0s 91us/step - loss: 0.0583 - acc: 1.0000\n",
      "Epoch 135/150\n",
      "2000/2000 [==============================] - 0s 93us/step - loss: 0.0572 - acc: 1.0000\n",
      "Epoch 136/150\n",
      "2000/2000 [==============================] - 0s 93us/step - loss: 0.0562 - acc: 1.0000\n",
      "Epoch 137/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.0551 - acc: 1.0000\n",
      "Epoch 138/150\n",
      "2000/2000 [==============================] - 0s 91us/step - loss: 0.0541 - acc: 1.0000\n",
      "Epoch 139/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.0532 - acc: 1.0000\n",
      "Epoch 140/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.0523 - acc: 1.0000\n",
      "Epoch 141/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.0513 - acc: 1.0000\n",
      "Epoch 142/150\n",
      "2000/2000 [==============================] - 0s 91us/step - loss: 0.0505 - acc: 1.0000\n",
      "Epoch 143/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.0496 - acc: 1.0000\n",
      "Epoch 144/150\n",
      "2000/2000 [==============================] - 0s 94us/step - loss: 0.0488 - acc: 1.0000\n",
      "Epoch 145/150\n",
      "2000/2000 [==============================] - 0s 93us/step - loss: 0.0480 - acc: 1.0000\n",
      "Epoch 146/150\n",
      "2000/2000 [==============================] - 0s 93us/step - loss: 0.0472 - acc: 1.0000\n",
      "Epoch 147/150\n",
      "2000/2000 [==============================] - 0s 93us/step - loss: 0.0465 - acc: 1.0000\n",
      "Epoch 148/150\n",
      "2000/2000 [==============================] - 0s 97us/step - loss: 0.0457 - acc: 1.0000\n",
      "Epoch 149/150\n",
      "2000/2000 [==============================] - 0s 91us/step - loss: 0.0450 - acc: 1.0000\n",
      "Epoch 150/150\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 0.0443 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb29a3e588>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import glorot_normal, normal\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=2,\n",
    "                units=2,\n",
    "                activation='sigmoid',\n",
    "                kernel_initializer=glorot_normal(seed=42),\n",
    "                name='hidden'))\n",
    "model.add(Dense(units=1,\n",
    "                activation='sigmoid',\n",
    "                kernel_initializer=normal(seed=42),\n",
    "                name='output'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.05), metrics=['acc'])\n",
    "\n",
    "model.fit(X, y, epochs=150, batch_size=16, callbacks=[replaydata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepreplay.replay import Replay\n",
    "\n",
    "replay = Replay(replay_filename='hyperparms_in_action.h5', group_name='part1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = replay.build_feature_space(ax, layer_name='hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.plot(epoch=60).savefig('feature_space_epoch60.png', dpi=120)\n",
    "fs.animate().save('feature_space_animation.mp4', dpi=120, fps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
